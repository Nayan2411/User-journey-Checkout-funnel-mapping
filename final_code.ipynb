{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed4a1222",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "import chart_studio.plotly as py\n",
    "import plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7edeface",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install chart_studio "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "138e99b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('downloads/user_journey_map_project/raw.csv')[\n",
    "    ['user_id', 'time_install', 'event_name', 'time_event']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "470a9602",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start with making sure that time_event and time_insrall are Pandas Datetime types:\n",
    "data['time_event'] = pd.to_datetime(data['time_event'])\n",
    "data['time_install'] = pd.to_datetime(data['time_install'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "222c1117",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure that there's no event occurring before time_install\n",
    "data = data[data.time_event >= data.time_install]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01557071",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The initial data Pandas DataFrame must have these 4 columns:\n",
    "# user_id | time_install | event_name | time_event\n",
    "# - user_id (string): the unique identifier of a user\n",
    "# - time_install (Pandas datetime): the time when the user installed the app (there should be 1 time_install per user_id)\n",
    "# - event_name (string): the name of a specific in-app event (there can be many event_name per user_id)\n",
    "# - time_event (Pandas datetime): the time of each event (there should be 1 time_event per user_id)\n",
    "\n",
    "# Edit this dataframe so that installs are passed as events\n",
    "\n",
    "# Create a new DF from the data DF containing only install data\n",
    "installs = data[['user_id', 'time_install']].sort_values(\n",
    "    'time_install').drop_duplicates('user_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a456687",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an install column containing dummy \"install\" events\n",
    "installs['event_name'] = 'install'\n",
    "\n",
    "# Create an event_type column to keep the information of install vs other events\n",
    "installs['event_type'] = 'install'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5911fd3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename time_install to time_event\n",
    "\n",
    "installs.rename(columns={'time_install': 'time_event'}, inplace=True)\n",
    "\n",
    "# In the data DF, keep only events data and create the event_type column\n",
    "data = data[['user_id', 'event_name',\n",
    "             'time_event']].drop_duplicates()\n",
    "data['event_type'] = 'in_app_action'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ac6e75b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate the two DataFrames\n",
    "data = pd.concat([data, installs[data.columns]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f72bef9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on the time of events, we can compute the rank of each action at the user_id level:\n",
    "\n",
    "# a) Sort ascendingly per user_id and time_event\n",
    "# sort by event_type to make sure installs come first\n",
    "data.sort_values(['user_id', 'event_type', 'time_event'],\n",
    "                 ascending=[True, False, True], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d6fedbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# b) Group by user_id\n",
    "grouped = data.groupby('user_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f770284",
   "metadata": {},
   "outputs": [],
   "source": [
    "# c) Define a ranking function based on time_event, using the method = 'first' param to ensure no events have the same rank\n",
    "def rank(x): return x['time_event'].rank(method='first').astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a48fce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# d) Apply the ranking function to the data DF into a new \"rank_event\" column\n",
    "data[\"rank_event\"] = grouped.apply(rank).reset_index(0, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "591a2e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add, each row, the information about the next_event\n",
    "\n",
    "# a) Regroup by user_id\n",
    "grouped = data.groupby('user_id')\n",
    "\n",
    "# b) The shift function allows to access the next row's data. Here, we'll want the event name\n",
    "\n",
    "\n",
    "def get_next_event(x): return x['event_name'].shift(-1)\n",
    "\n",
    "\n",
    "# c) Apply the function into a new \"next_event\" column\n",
    "data[\"next_event\"] = grouped.apply(\n",
    "    lambda x: get_next_event(x)).reset_index(0, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea867a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Likewise, we can compute time from each event to its next event:\n",
    "\n",
    "# a) Regroup by user_id\n",
    "grouped = data.groupby('user_id')\n",
    "\n",
    "# b) We make use one more time of the shift function:\n",
    "\n",
    "\n",
    "def get_time_diff(\n",
    "    x): return x['time_event'].shift(-1) - x['time_event']\n",
    "\n",
    "\n",
    "# c) Apply the function to the data DF into a new \"time_to_next\" column\n",
    "data[\"time_to_next\"] = grouped.apply(\n",
    "    lambda x: get_time_diff(x)).reset_index(0, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "374859a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we'll plot the journey up to the 10th action. This can be achieved by filtering the dataframe based on the rank_event column that we computed:\n",
    "data = data[data.rank_event < 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef7f9b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that you have only installs at rank 1:\n",
    "data[data['rank_event'] == 1].event_name.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b8b6bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Working on the nodes_dict\n",
    "\n",
    "all_events = list(data.event_name.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f51782",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a set of colors that you'd like to use in your plot.\n",
    "palette = ['50BE97', 'E4655C', 'FCC865',\n",
    "           'BFD6DE', '3E5066', '353A3E', 'E6E6E6']\n",
    "#  Here, I passed the colors as hex, but we need to pass it as RGB. This loop will do:\n",
    "for i, col in enumerate(palette):\n",
    "    palette[i] = tuple(int(col[i:i+2], 16) for i in (0, 2, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "355b05c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append a Seaborn complementary palette to your palette in case you did not provide enough colors to style every event\n",
    "complementary_palette = sns.color_palette(\n",
    "    \"deep\", len(all_events) - len(palette))\n",
    "if len(complementary_palette) > 0:\n",
    "    palette.extend(complementary_palette)\n",
    "\n",
    "output = dict()\n",
    "output.update({'nodes_dict': dict()})\n",
    "\n",
    "i = 0\n",
    "for rank_event in data.rank_event.unique():  # For each rank of event...\n",
    "    # Create a new key equal to the rank...\n",
    "    output['nodes_dict'].update(\n",
    "        {rank_event: dict()}\n",
    "    )\n",
    "\n",
    "    # Look at all the events that were done at this step of the funnel...\n",
    "    all_events_at_this_rank = data[data.rank_event ==\n",
    "                                   rank_event].event_name.unique()\n",
    "\n",
    "    # Read the colors for these events and store them in a list...\n",
    "    rank_palette = []\n",
    "    for event in all_events_at_this_rank:\n",
    "        rank_palette.append(palette[list(all_events).index(event)])\n",
    "\n",
    "    # Keep trace of the events' names, colors and indices.\n",
    "    output['nodes_dict'][rank_event].update(\n",
    "        {\n",
    "            'sources': list(all_events_at_this_rank),\n",
    "            'color': rank_palette,\n",
    "            'sources_index': list(range(i, i+len(all_events_at_this_rank)))\n",
    "        }\n",
    "    )\n",
    "    # Finally, increment by the length of this rank's available events to make sure next indices will not be chosen from existing ones\n",
    "    i += len(output['nodes_dict'][rank_event]['sources_index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c70f74fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Working on the links_dict\n",
    "\n",
    "output.update({'links_dict': dict()})\n",
    "\n",
    "# Group the DataFrame by user_id and rank_event\n",
    "grouped = data.groupby(['user_id', 'rank_event'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d615e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to read the souces, targets, values and time from event to next_event:\n",
    "\n",
    "\n",
    "def update_source_target(user):\n",
    "    try:\n",
    "        source_index = output['nodes_dict'][user.name[1]]['sources_index'][output['nodes_dict']\n",
    "                                                                           [user.name[1]]['sources'].index(user['event_name'].values[0])]\n",
    "\n",
    "        target_index = output['nodes_dict'][user.name[1] + 1]['sources_index'][output['nodes_dict']\n",
    "                                                                               [user.name[1] + 1]['sources'].index(user['next_event'].values[0])]\n",
    "\n",
    "        if source_index in output['links_dict']:\n",
    "            if target_index in output['links_dict'][source_index]:\n",
    "\n",
    "                output['links_dict'][source_index][target_index]['unique_users'] += 1\n",
    "                output['links_dict'][source_index][target_index]['avg_time_to_next'] += user['time_to_next'].values[0]\n",
    "            else:\n",
    "\n",
    "                output['links_dict'][source_index].update({target_index:\n",
    "                                                           dict(\n",
    "                                                               {'unique_users': 1,\n",
    "                                                                'avg_time_to_next': user['time_to_next'].values[0]}\n",
    "                                                           )\n",
    "                                                           })\n",
    "        else:\n",
    "\n",
    "            output['links_dict'].update({source_index: dict({target_index: dict(\n",
    "                {'unique_users': 1, 'avg_time_to_next': user['time_to_next'].values[0]})})})\n",
    "    except Exception as e:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc649e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the function to your grouped Pandas object:\n",
    "grouped.apply(lambda user: update_source_target(user))\n",
    "\n",
    "\n",
    "targets = []\n",
    "sources = []\n",
    "values = []\n",
    "time_to_next = []\n",
    "\n",
    "for source_key, source_value in output['links_dict'].items():\n",
    "    for target_key, target_value in output['links_dict'][source_key].items():\n",
    "        sources.append(source_key)\n",
    "        targets.append(target_key)\n",
    "        values.append(target_value['unique_users'])\n",
    "        time_to_next.append(str(pd.to_timedelta(\n",
    "            target_value['avg_time_to_next'] / target_value['unique_users'])).split('.')[0])  # Split to remove the milliseconds information\n",
    "\n",
    "labels = []\n",
    "colors = []\n",
    "for key, value in output['nodes_dict'].items():\n",
    "    labels = labels + list(output['nodes_dict'][key]['sources'])\n",
    "    colors = colors + list(output['nodes_dict'][key]['color'])\n",
    "\n",
    "for idx, color in enumerate(colors):\n",
    "    colors[idx] = \"rgb\" + str(color) + \"\"\n",
    "\n",
    "fig = go.Figure(data=[go.Sankey(\n",
    "    node=dict(\n",
    "        thickness=10,  # default is 20\n",
    "        line=dict(color=\"black\", width=0.5),\n",
    "        label=labels,\n",
    "        color=colors\n",
    "    ),\n",
    "    link=dict(\n",
    "        source=sources,\n",
    "        target=targets,\n",
    "        value=values,\n",
    "        label=time_to_next,\n",
    "        hovertemplate='%{value} unique users went from %{source.label} to %{target.label}.<br />' +\n",
    "        '<br />It took them %{label} in average.<extra></extra>',\n",
    "    ))])\n",
    "\n",
    "fig.update_layout(autosize=True, title_text=\"Medium app\",\n",
    "                  font=dict(size=15), plot_bgcolor='white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "803d3493",
   "metadata": {},
   "outputs": [],
   "source": [
    "publish_to_web = True\n",
    "if publish_to_web:\n",
    "    py.iplot(fig, filename='user_journey')\n",
    "else:\n",
    "    fig.show(renderer='chrome')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0997e9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98308220",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
